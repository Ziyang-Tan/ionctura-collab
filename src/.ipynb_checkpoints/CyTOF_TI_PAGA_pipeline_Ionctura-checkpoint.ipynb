{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fcsy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pp/85_9j6m55sv_gmz3y6b_nmv80000gn/T/ipykernel_53900/3405433206.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manndata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfcsy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fcsy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import scanpy as sc\n",
    "import os\n",
    "import anndata\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from fcsy import DataFrame\n",
    "import matplotlib\n",
    "from glob import glob\n",
    "matplotlib.rcParams['pdf.fonttype']=42\n",
    "matplotlib.rcParams['ps.fonttype']=42\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from igraph import InternalError\n",
    "\n",
    "# scanpy settings\n",
    "sc.settings.verbosity = 0  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.settings.set_figure_params(dpi=150, frameon=False, figsize=(4, 4)) \n",
    "sc._settings.ScanpyConfig.n_jobs=4 # useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readin the information table\n",
    "info_path = 'data/EXP-21-DG3656_Sample info_New batch _iOnctura.xlsx'\n",
    "sampleInfo = pd.read_excel(info_path, dtype={'Facility barcode/Sample ID':str})\n",
    "sampleInfo = sampleInfo[sampleInfo['Patient ID']!='Empty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectInfo = sampleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = '/Users/tan/cytof_data/*/renamed'\n",
    "labelDir = '/Users/tan/cytof_data/*/classifiedV3'\n",
    "nsample = 3000\n",
    "sub_name = 'Tregs'\n",
    "\n",
    "drop_columns = ['Time', 'Event_length', 'Center', 'Width', 'Residual', 'Offset',\n",
    "                'Amplitude', '88Sr', 'CD45', '102Pd', '103Rh', '104Pd', '105Pd',\n",
    "                '106Pd', '108Pd','116Cd', '120Sn', '127I', '131Xe', '138Ba',\n",
    "                '190BCKG', '191Ir', '193Ir', '208Pb']\n",
    "drop_dic = {'pDC': [], \n",
    "            'B-cells': ['CD33', 'CD3', 'TCRgd', 'Siglec-8', 'CD14', 'CD141', 'CD4'],\n",
    "            'CD4 T-cells': ['IgD', 'CD1c', 'TCRgd', 'Siglec-8', 'CD20', 'CD14'],\n",
    "            'CD8 T-cells': ['IgD', 'CD11c', 'CD1c', 'TCRgd', 'Siglec-8', 'CD20', 'CD14'],\n",
    "            #'Eosinophils': ['IgD', 'CD57', 'CD25', 'TCRgd', 'CD14'],\n",
    "            'Monocytes': ['CD57', 'IgD', 'CD25', 'CD20', 'TCRgd', 'CD22', 'CD127'], \n",
    "            'Neutrophils': ['IgD', 'HLA-DR', 'CD57', 'CD25', 'CD22', 'TCRgd', 'CD123', 'CD161'],\n",
    "            'NK cells': [],\n",
    "            'Lin Neg': [],\n",
    "            'gdT': [], \n",
    "            'Plasmablasts': [],\n",
    "            'Basophils': [],\n",
    "            'Tregs':[]}\n",
    "\n",
    "# readin and merge the file according to \"selectInfo\" as an anndata object\n",
    "all_data_path = 'adata/ion_EXP-21-DG3656_V3.h5ad'\n",
    "\n",
    "#for sub_name in drop_dic:\n",
    "print('currently working on ' + sub_name)\n",
    "if not os.path.exists(all_data_path):\n",
    "    print('adata not found, load and preprocess raw data...')\n",
    "    all_data_list = []\n",
    "    all_label_list = []\n",
    "    for i in range(len(selectInfo)):\n",
    "        label_path = glob(labelDir + '/*/' + str(selectInfo['Facility barcode/Sample ID'].iloc[i]) + '*.csv')[0]\n",
    "        data_path = glob(dataDir + '/*/' + str(selectInfo['Facility barcode/Sample ID'].iloc[i]) + '*.fcs')[0]\n",
    "        labelTmp = pd.read_csv(label_path)\n",
    "        labelTmp['Sample ID'] = np.repeat(str(selectInfo['Facility barcode/Sample ID'].iloc[i]), len(labelTmp.index))\n",
    "        labelTmp['timepoint'] = np.repeat(str(selectInfo['Time point '].iloc[i]), len(labelTmp.index))\n",
    "        labelTmp['Subject ID'] = np.repeat(str(selectInfo['Patient ID'].iloc[i]), len(labelTmp.index))\n",
    "        labelTmp['group'] = np.repeat(str(selectInfo['Cohort and dose'].iloc[i]), len(labelTmp.index))\n",
    "        labelTmp['type'] = np.repeat(str(selectInfo['Tumor type'].iloc[i]), len(labelTmp.index))\n",
    "        labelTmp['timepoint_group'] = np.repeat(selectInfo['Time point '].iloc[i] + \n",
    "                                                '_' + \n",
    "                                                str(selectInfo['Cohort and dose'].iloc[i]), len(labelTmp.index))\n",
    "        labelTmp['batch'] = np.repeat(data_path.split('/')[-4], len(labelTmp.index)) #EXP-XX-XXXXXX\n",
    "        dataTmp = DataFrame.from_fcs(data_path, channel_type='long')\n",
    "        if '4-1BB' in set(dataTmp.columns):\n",
    "            dataTmp.rename(columns={\"4-1BB\": \"CD137\"}, inplace=True)\n",
    "        # filter the cells without a level1 tag\n",
    "        dataTmp = dataTmp[labelTmp['level1']!=' ']\n",
    "        labelTmp = labelTmp[labelTmp['level1']!=' ']\n",
    "        # remove EQBeads and DNA channel # also remove the negative channels\n",
    "        dataTmp.drop(columns=drop_columns, inplace=True)\n",
    "        #dataTmp = dataTmp[select_columns]\n",
    "        dataTmp = np.arcsinh(dataTmp/5)\n",
    "        all_data_list.append(dataTmp)\n",
    "        all_label_list.append(labelTmp)\n",
    "\n",
    "    all_data = pd.concat(all_data_list, ignore_index=True)\n",
    "    all_label = pd.concat(all_label_list, ignore_index=True)\n",
    "    adata = anndata.AnnData(all_data)\n",
    "    adata.obs = all_label\n",
    "    #print('batch correction...')\n",
    "    #sc.pp.combat(adata, key = 'batch', covariates = ['timepoint'])\n",
    "    print('scaling...')\n",
    "    sc.pp.scale(adata)\n",
    "    os.makedirs('adata/', exist_ok=True)\n",
    "    print('write to h5ad file...')\n",
    "    adata.write(filename=all_data_path, compression = 'gzip')\n",
    "    adata=None\n",
    "    print('finished!')\n",
    "print('loading...')\n",
    "adata_all = sc.read_h5ad(filename = all_data_path)\n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_all.obs['Sample ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', adata_all.obs['Sample ID'].nunique()+1)\n",
    "adata_all.obs[adata_all.obs['level3'].isin(['CD39 Memory Tregs', 'Memory Tregs', 'Naive Tregs'])]['Sample ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsampling\n",
    "print('subsampling...')\n",
    "try:\n",
    "    if sub_name in adata_all.obs['level1'].unique().tolist():\n",
    "        sample_index = adata_all.obs[adata_all.obs['level1']==sub_name].groupby('Sample ID').apply(lambda x: x.sample(n=nsample, random_state=0) if x.shape[0]>=nsample else x).index.droplevel(level=0)\n",
    "    elif sub_name in adata_all.obs['level2'].unique().tolist():\n",
    "        sample_index = adata_all.obs[adata_all.obs['level2']==sub_name].groupby('Sample ID').apply(lambda x: x.sample(n=nsample, random_state=0) if x.shape[0]>=nsample else x).index.droplevel(level=0)\n",
    "    elif sub_name == 'Tregs':\n",
    "        sample_index = adata_all.obs[adata_all.obs['level3'].isin(['CD39 Memory Tregs', 'Memory Tregs', 'Naive Tregs'])].groupby('Sample ID').apply(lambda x: x.sample(n=nsample, random_state=0) if x.shape[0]>=nsample else x).index.droplevel(level=0)        \n",
    "    adata_sample = adata_all[sample_index]\n",
    "except ValueError as e: \n",
    "    # usually when no file has more cells than nsample and thus no subsampling at all.\n",
    "    # so the results after apply will not be a multiplex index and the droplevel func will fail.\n",
    "    print(e)\n",
    "    if sub_name in adata_all.obs['level1'].unique().tolist():\n",
    "        adata_sample = adata_all[adata_all.obs['level1']==sub_name]\n",
    "    elif sub_name in adata_all.obs['level2'].unique().tolist():\n",
    "        adata_sample = adata_all[adata_all.obs['level2']==sub_name]\n",
    "    elif sub_name == 'Tregs':\n",
    "        adata_sample = adata_all[adata_all.obs['level3'].isin(['CD39 Memory Tregs', 'Memory Tregs', 'Naive Tregs'])]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata.AnnData(adata_sample.to_df().drop(columns = drop_dic[sub_name]))\n",
    "adata.obs = pd.DataFrame(adata_sample.obs)\n",
    "\n",
    "# skip\n",
    "# optimization\n",
    "#sc.settings.figdir='./optimization/'\n",
    "#for res in [0.3]:\n",
    "#    adata_opt = adata\n",
    "#    n_comps = min([adata_opt.n_obs, adata_opt.n_vars, 21])-1\n",
    "#    sc.tl.pca(adata_opt, svd_solver='arpack', n_comps=n_comps)\n",
    "#    sc.pp.neighbors(adata_opt, n_neighbors=10, n_pcs=n_comps)\n",
    "#    sc.tl.leiden(adata_opt, resolution=res)\n",
    "#    sc.tl.paga(adata_opt, groups='leiden')\n",
    "#    sc.pl.paga(adata_opt, color=['leiden'], threshold=0.1, show=False, \n",
    "#               save='_' + sub_name + '_' + str(res) + '.pdf')\n",
    "#    adata_opt = []\n",
    "\n",
    "# save figures to a sub dir\n",
    "figpath='./figures/' + sub_name + '/'\n",
    "os.makedirs(figpath, exist_ok=True)\n",
    "sc.settings.figdir=figpath\n",
    "\n",
    "print('calculating PAGA...')\n",
    "n_comps = min([adata.n_obs, adata.n_vars, 21])-1\n",
    "sc.tl.pca(adata, svd_solver='arpack', n_comps=n_comps)\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=n_comps)\n",
    "\n",
    "# paga process\n",
    "sc.tl.leiden(adata, resolution=0.3) \n",
    "\n",
    "sc.tl.paga(adata, groups='leiden')\n",
    "try:\n",
    "    sc.pl.paga(adata, color=['leiden'], threshold=0.1, show=False, \n",
    "               save='_' + sub_name + '.pdf')\n",
    "except InternalError as e: # maybe there're too little cells\n",
    "    print(e)\n",
    "    sc.pl.paga(adata, color=['leiden'], show=False, \n",
    "               save='_' + sub_name + '.pdf')        \n",
    "\n",
    "print('embedding with FA...')\n",
    "sc.tl.draw_graph(adata, init_pos='paga')\n",
    "\n",
    "sc.pl.draw_graph(adata, color=['timepoint', 'group', 'leiden', 'batch', 'Subject ID', 'type'], show=False,\n",
    "                 save='_' + sub_name + '.pdf')\n",
    "\n",
    "sc.pl.draw_graph(adata, color=adata.var.index.values, show=False,\n",
    "                 save='_' + sub_name + '_markers.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('embedding with density plot...')\n",
    "\n",
    "sc.tl.embedding_density(adata, basis='draw_graph_fa', groupby='timepoint')\n",
    "sc.pl.embedding_density(adata, basis='draw_graph_fa', key='draw_graph_fa_density_timepoint', \n",
    "                        group=['AC1D1', 'AC1D2', 'AC1D15', 'AC2D1', 'AC3D1', 'AC4D1',\n",
    "                               'AC5D1','AC6D1','AC7D1','AC8D1','AC9D1','AC10D1','AC11D1',\n",
    "                               'AC12D1','AC13D1','AC14D1','AC15D1','AC17D1','AC18D1',], show=False, \n",
    "                        save='_' + sub_name + '_timepoint_density.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('saving results...')\n",
    "os.makedirs('PAGA_result_data/', exist_ok=True)\n",
    "adata.write(filename='PAGA_result_data/EXP-21-DG3656_' + sub_name + '_sample3000.h5ad', compression = 'gzip')\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(adata_all.obs['timepoint'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
